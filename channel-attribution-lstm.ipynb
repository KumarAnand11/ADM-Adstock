{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"channel-attribution-lstm.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"KxXgSDYOGZEs","colab_type":"code","colab":{}},"source":["# Implementation of multi-touch multi-channel attribution model using LSTM with attention\n","#\n","# Ning li, Sai Kumar Arava, Chen Dong, Zhenyu Yan, Abhishek Pani, Deep Neural Net with Attention for Multi-channel Multi-touch Attribution\n","# Kan Ren, et al, Learning Multi-touch Conversion Attribution with Dual-attention Mechanisms for Online Advertising\n","#\n","# Input dataset:\n","# http://ailab.criteo.com/criteo-attribution-modeling-bidding-dataset/\n","# or\n","# https://drive.google.com/file/d/1vvngMlMomaPODdKCOdL-3scj2Vv_JhTm/view"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WcdpXQEnGZE9","colab_type":"text"},"source":["### Data description\n","This dataset represents a sample of 30 days of Criteo live traffic data. Each line corresponds to one impression (a banner) that was displayed to a user. For each banner we have detailed information about the context, if it was clicked, if it led to a conversion and if it led to a conversion that was attributed to Criteo or not. Data has been sub-sampled and anonymized so as not to disclose proprietary elements.\n","\n","Here is a detailed description of the fields (they are tab-separated in the file):\n","\n","* timestamp: timestamp of the impression (starting from 0 for the first impression). The dataset is sorted according to timestamp.\n","* uid: a unique user identifier\n","* campaign: a unique identifier for the campaign\n","* conversion: 1 if there was a conversion in the 30 days after the impression (independently of whether this impression was last click or not)\n","* conversion_timestamp: the timestamp of the conversion or -1 if no conversion was observed\n","* conversion_id: a unique identifier for each conversion (so that timelines can be reconstructed if needed). -1 if there was no conversion\n","* attribution: 1 if the conversion was attributed to Criteo, 0 otherwise\n","* click: 1 if the impression was clicked, 0 otherwise\n","* click_pos: the position of the click before a conversion (0 for first-click)\n","* click_nb: number of clicks. More than 1 if there was several clicks before a conversion\n","* cost: the price paid by Criteo for this display (disclaimer: not the real price, only a transformed version of it)\n","* cpo: the cost-per-order in case of attributed conversion (disclaimer: not the real price, only a transformed version of it)\n","* time_since_last_click: the time since the last click (in s) for the given impression\n","* cat(1-9): contextual features associated to the display. Can be used to learn the click/conversion models. We do not disclose the meaning of these features but it is not relevant for this study. Each column is a categorical variable. In the experiments, they are mapped to a fixed dimensionality space using the Hashing Trick (see paper for reference).\n","\n","### Key figures\n","* 2.4Gb uncompressed\n","* 16.5M impressions\n","* 45K conversions\n","* 700 campaigns"]},{"cell_type":"code","metadata":{"id":"kGzrW5gaGZE_","colab_type":"code","outputId":"ef8386e7-2416-4694-b821-3830c281105b","executionInfo":{"status":"ok","timestamp":1579913299897,"user_tz":300,"elapsed":3592,"user":{"displayName":"Uthsav Shetty","photoUrl":"","userId":"13721007547040045381"}},"colab":{"base_uri":"https://localhost:8080/","height":152}},"source":["import pandas as pd\n","import matplotlib.pyplot as plt \n","import numpy as np\n","\n","from sklearn.utils import resample\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","import tensorflow.compat.v1 as tf\n","tf.disable_v2_behavior()\n","\n","import keras\n","\n","plt.style.use('ggplot')"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"F3edcde0GZFL","colab_type":"code","colab":{}},"source":["\n","# Initial data preparation\n","\n","def add_derived_columns(df):\n","    df_ext = df.copy()\n","    df_ext['jid'] = df_ext['uid'].map(str) + '_' + df_ext['conversion_id'].map(str)\n","    \n","    min_max_scaler = MinMaxScaler()\n","    for cname in ('timestamp', 'time_since_last_click'):\n","        x = df_ext[cname].values.reshape(-1, 1) \n","        df_ext[cname + '_norm'] = min_max_scaler.fit_transform(x)\n","    \n","    return df_ext\n","\n","def filter_journeys_by_length(df, min_touchpoints):\n","    if min_touchpoints <= 1:\n","        return df\n","    else:\n","        grouped = df.groupby(['jid'])['uid'].count().reset_index(name=\"count\")\n","        return df[df['jid'].isin( grouped[grouped['count'] >= min_touchpoints]['jid'].values )]\n","\n","def sample_campaigns(df, n_campaigns):    \n","    campaigns = np.random.choice( df['campaign'].unique(), n_campaigns, replace = False )\n","    return df[ df['campaign'].isin(campaigns) ]\n","\n","def balance_conversions(df):\n","    df_minority = df[df.conversion == 1]\n","    df_majority = df[df.conversion == 0]\n","    \n","    df_majority_jids = np.array_split(df_majority['jid'].unique(), 100 * df_majority.shape[0]/df_minority.shape[0] )\n","    \n","    df_majority_sampled = pd.DataFrame(data=None, columns=df.columns)\n","    for jid_chunk in df_majority_jids:\n","        df_majority_sampled = pd.concat([df_majority_sampled, df_majority[df_majority.jid.isin(jid_chunk)]])\n","        if df_majority_sampled.shape[0] > df_minority.shape[0]:\n","            break\n","    \n","    return pd.concat([df_majority_sampled, df_minority]).sample(frac=1).reset_index(drop=True)\n","\n","def map_one_hot(df, column_names, result_column_name):\n","    mapper = {} \n","    for i, col_name in enumerate(column_names):\n","        for val in df[col_name].unique():\n","            mapper[str(val) + str(i)] = len(mapper)\n","         \n","    df_ext = df.copy()\n","    \n","    def one_hot(values):\n","        v = np.zeros( len(mapper) )\n","        for i, val in enumerate(values): \n","            v[ mapper[str(val) + str(i)] ] = 1\n","        return v    \n","    \n","    df_ext[result_column_name] = df_ext[column_names].values.tolist()\n","    df_ext[result_column_name] = df_ext[result_column_name].map(one_hot)\n","    \n","    return df_ext\n","    \n","data_file ='criteo_attribution_dataset.tsv.gz'\n","df0 = pd.read_csv(data_file, sep='\\t', compression='gzip')\n","\n","n_campaigns = 400\n","\n","df1 = add_derived_columns(df0)\n","df2 = sample_campaigns(df1, n_campaigns)\n","df3 = filter_journeys_by_length(df2, 2)\n","df4 = balance_conversions(df3)\n","df5 = map_one_hot(df4, ['cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat8'], 'cats')\n","df6 = map_one_hot(df5, ['campaign'], 'campaigns').sort_values(by=['timestamp_norm'])\n","\n","print(df6.shape[0])\n","print([df6[df6.conversion == 0].shape[0], df6[df6.conversion == 1].shape[0]])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5JommGeeGZFb","colab_type":"code","colab":{}},"source":["# Data exploration\n","\n","def journey_lenght_histogram(df):\n","    counts = df.groupby(['jid'])['uid'].count().reset_index(name=\"count\").groupby(['count']).count()\n","    return counts.index, counts.values / df.shape[0]\n","\n","hist_x, hist_y = journey_lenght_histogram(df4)\n","\n","plt.plot(range(len(hist_all)), hist_all, label='all journeys')\n","plt.yscale('log')\n","plt.xlim(0, 120)\n","plt.xlabel('Journey length (number of touchpoints)')\n","plt.ylabel('Fraction of journeys')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nNQdfBH-GZFn","colab_type":"text"},"source":["## Last Touch Attribution"]},{"cell_type":"code","metadata":{"id":"q2GoIX3gGZFp","colab_type":"code","colab":{}},"source":["def last_touch_attribution(df):\n","    \n","    def count_by_campaign(df):\n","        counters = np.zeros(n_campaigns)\n","        for campaign_one_hot in df['campaigns'].values:\n","            campaign_id = np.argmax(campaign_one_hot)\n","            counters[campaign_id] = counters[campaign_id] + 1\n","        return counters\n","        \n","    campaign_impressions = count_by_campaign(df)\n","    \n","    df_converted = df[df['conversion'] == 1]\n","    idx = df_converted.groupby(['jid'])['timestamp_norm'].transform(max) == df_converted['timestamp_norm']\n","    campaign_conversions = count_by_campaign(df_converted[idx])\n","        \n","    return campaign_conversions / campaign_impressions\n","    \n","lta = last_touch_attribution(df6)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aw7bkSofGZFw","colab_type":"code","colab":{}},"source":["# Visualization of the attribution scores\n","\n","campaign_idx = range(150, 200)\n","\n","fig = plt.figure(figsize=(15,4))\n","ax = fig.add_subplot(111)\n","plt.bar( range(len(lta[campaign_idx])), lta[campaign_idx], label='LTA' )\n","plt.xlabel('Campaign ID')\n","plt.ylabel('Return per impression')\n","plt.legend(loc='upper left')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hVTHN07OGZF5","colab_type":"text"},"source":["## Logistic Regression"]},{"cell_type":"code","metadata":{"id":"0U0Wncz5GZF7","colab_type":"code","colab":{}},"source":["def features_for_logistic_regression(df):\n","\n","    def pairwise_max(series):\n","        return np.max(series.tolist(), axis = 0).tolist()\n","    \n","    aggregation = {\n","        'campaigns': pairwise_max,\n","        'cats': pairwise_max,\n","        'click': 'sum',\n","        'cost': 'sum',\n","        'conversion': 'max'\n","    }\n","    \n","    df_agg = df.groupby(['jid']).agg(aggregation)\n","    \n","    df_agg['features'] = df_agg[['campaigns', 'cats', 'click', 'cost']].values.tolist()\n","    \n","    return (\n","        np.stack(df_agg['features'].map(lambda x: np.hstack(x)).values),\n","        df_agg['conversion'].values\n","    )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xgqrSymyGZGD","colab_type":"code","colab":{}},"source":["x, y = features_for_logistic_regression(df6)\n","print(np.shape(x))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LsKfOBQUGZGK","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 1)\n","x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.20, random_state = 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"h5rZLwOQGZGS","colab_type":"code","colab":{}},"source":["# Quick sanity check\n","from sklearn.linear_model import LogisticRegression\n","\n","logisticRegr = LogisticRegression()\n","logisticRegr.fit(x_train, y_train)\n","score = logisticRegr.score(x_test, y_test)\n","print(score)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YeIQZw7OGZGb","colab_type":"code","colab":{}},"source":["from keras.models import Sequential \n","from keras.layers import Dense, Dropout\n","from keras.constraints import NonNeg\n","\n","m = np.shape(x)[1]\n","    \n","model = Sequential()  \n","model.add(Dense(1, input_dim=m, activation='sigmoid', name = 'contributions')) \n","\n","model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy']) \n","history = model.fit(x_train, y_train, batch_size=128, epochs=10, verbose=1, validation_data=(x_val, y_val)) \n","score = model.evaluate(x_test, y_test, verbose=0) \n","print('Test score:', score[0]) \n","print('Test accuracy:', score[1])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k0ea3a9QGZGl","colab_type":"code","colab":{}},"source":["# Visualization of the attribution scores\n","from sklearn.utils.extmath import softmax\n","\n","keras_logreg = model.get_layer('contributions').get_weights()[0].flatten()[0:n_campaigns]\n","keras_logreg = softmax([keras_logreg]).flatten()\n","\n","fig = plt.figure(figsize=(15,4))\n","ax = fig.add_subplot(111)\n","plt.bar(range(len(keras_logreg[campaign_idx])), keras_logreg[campaign_idx] )\n","plt.xlabel('Campaign ID')\n","plt.ylabel('Return per impression')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d4OUjfLCGZGx","colab_type":"text"},"source":["## Basic LSTM"]},{"cell_type":"code","metadata":{"id":"ata9uefQGZG2","colab_type":"code","colab":{}},"source":["def features_for_lstm(df, max_touchpoints):\n","    \n","    df_proj = df[['jid', 'campaigns', 'cats', 'click', 'cost', 'time_since_last_click_norm', 'timestamp_norm', 'conversion']]\n","    \n","    x2d = df_proj.values\n","    \n","    x3d_list = np.split(x2d[:, 1:], np.cumsum(np.unique(x2d[:, 0], return_counts=True)[1])[:-1])\n","    \n","    x3d = []\n","    y = []\n","    for xi in x3d_list:\n","        journey_matrix = np.apply_along_axis(np.hstack, 1, xi)\n","        journey_matrix = journey_matrix[ journey_matrix[:, 5].argsort() ] # sort impressions by timestamp\n","        n_touchpoints = len(journey_matrix)\n","        padded_journey = []\n","        if(n_touchpoints >= max_touchpoints):\n","            padded_journey = journey_matrix[0:max_touchpoints]\n","        else:\n","            padded_journey = np.pad(journey_matrix, ((0, max_touchpoints - n_touchpoints), (0, 0)), 'constant', constant_values=(0))\n","            \n","        x3d.append(padded_journey[:, 0:-1])\n","        y.append(np.max(padded_journey[:, -1]))\n","        \n","    return np.stack(x3d), y\n","\n","x, y = features_for_lstm(df6, max_touchpoints = 15)\n","print(np.shape(x))\n","\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 1)\n","x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.20, random_state = 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ttUaaP5rGZHE","colab_type":"code","colab":{}},"source":["from keras.models import Sequential \n","from keras.layers import Dense, LSTM\n","\n","n_steps, n_features = np.shape(x)[1:3]\n","    \n","model = Sequential() \n","model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2, input_shape=(n_steps, n_features)))\n","model.add(Dense(1, activation='sigmoid')) \n","\n","model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy']) \n","history = model.fit(x_train, y_train, batch_size=64, epochs=5, verbose=1, validation_data=(x_val, y_val)) \n","score = model.evaluate(x_test, y_test, verbose=0) \n","print('Test score:', score[0]) \n","print('Test accuracy:', score[1])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9RV7IpPpGZHV","colab_type":"text"},"source":["## LSTM with Attention"]},{"cell_type":"code","metadata":{"id":"npKCA0d7GZHk","colab_type":"code","colab":{}},"source":["from keras.models import Sequential \n","from keras.layers import Dense, LSTM, Input, Lambda, RepeatVector, Permute, Flatten, Activation, Multiply\n","from keras.constraints import NonNeg\n","from keras import backend as K\n","from keras.models import Model\n","\n","n_steps, n_features = np.shape(x)[1:3]\n","\n","hidden_units = 64\n","\n","main_input = Input(shape=(n_steps, n_features))\n","    \n","embeddings = Dense(128, activation='linear', input_shape=(n_steps, n_features))(main_input)\n","\n","activations = LSTM(hidden_units, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(embeddings)\n","\n","attention = Dense(1, activation='tanh')(activations)\n","attention = Flatten()(attention)\n","attention = Activation('softmax', name = 'attention_weigths')(attention)\n","attention = RepeatVector(hidden_units * 1)(attention)\n","attention = Permute([2, 1])(attention)\n","\n","weighted_activations = Multiply()([activations, attention])\n","weighted_activations = Lambda(lambda xin: K.sum(xin, axis=-2), output_shape=(hidden_units,))(weighted_activations)\n","\n","main_output = Dense(1, activation='sigmoid')(weighted_activations)\n","\n","model = Model(inputs=main_input, outputs=main_output)\n","\n","model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy']) \n","history = model.fit(x_train, y_train, batch_size=64, epochs=5, verbose=1, validation_data=(x_val, y_val)) \n","score = model.evaluate(x_test, y_test, verbose=0) \n","print('Test score:', score[0]) \n","print('Test accuracy:', score[1])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VCj35mqgGZHv","colab_type":"text"},"source":["## Analysis of LSTM-A Model"]},{"cell_type":"code","metadata":{"id":"vI-x5aQdGZHy","colab_type":"code","colab":{}},"source":["def get_campaign_id(x_journey_step):\n","    return np.argmax(x_journey_step[0:n_campaigns])\n","\n","attention_model = Model(inputs=model.input, outputs=model.get_layer('attention_weigths').output)\n","\n","a = attention_model.predict(x_train)\n","\n","attributions = np.zeros(n_campaigns)\n","campaign_freq = np.ones(n_campaigns)\n","for i, journey in enumerate(a):\n","    for step, step_contribution in enumerate(journey):\n","        if(np.sum(x_train[i][step]) > 0):\n","            campaign_id = get_campaign_id(x_train[i][step])\n","            attributions[campaign_id] = attributions[campaign_id] + step_contribution\n","            campaign_freq[campaign_id] = campaign_freq[campaign_id] + 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"88V467YsGZH7","colab_type":"code","colab":{}},"source":["lstm_a = (attributions/campaign_freq)\n","\n","fig = plt.figure(figsize=(15, 4))\n","ax = fig.add_subplot(111)\n","plt.bar( range(len(lstm_a[campaign_idx])), lstm_a[campaign_idx], label='LSTM-A' )\n","plt.xlabel('Campaign ID')\n","plt.ylabel('Contribution')\n","plt.legend(loc='upper left')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9dtBpJqtGZIE","colab_type":"code","colab":{}},"source":["fig = plt.figure(figsize=(15, 4))\n","ax = fig.add_subplot(111)\n","\n","ratio = max(lta[idx]) / max(keras_logreg[idx])\n","plt.bar(np.linspace(0, len(campaign_idx), len(campaign_idx)), lta[campaign_idx], width=0.4, alpha=0.7, label='LTA' )\n","plt.bar(np.linspace(0, len(campaign_idx), len(campaign_idx)) - 0.3, keras_logreg[campaign_idx], width=0.4, alpha=0.7, label='Keras Log Reg' )\n","plt.xlabel('Campaign ID')\n","plt.ylabel('Contribution')\n","plt.legend(loc='upper left')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0B19zZ2pGZIO","colab_type":"code","colab":{}},"source":["fig = plt.figure(figsize=(15, 4))\n","ax = fig.add_subplot(111)\n","\n","ratio = max(lta[campaign_idx]) / max(lstm_a[campaign_idx])\n","plt.bar(np.linspace(0, len(campaign_idx), len(campaign_idx)), lta[campaign_idx], width=0.4, alpha=0.7, label='LTA' )\n","plt.bar(np.linspace(0, len(campaign_idx), len(campaign_idx)) - 0.3, lstm_a[campaign_idx], width=0.4, alpha=0.7, label='LSTM-A'  )\n","plt.xlabel('Campaign ID')\n","plt.ylabel('Contribution')\n","plt.legend(loc='upper left')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aVMy46clGZIb","colab_type":"text"},"source":["## Simulation"]},{"cell_type":"code","metadata":{"id":"-3RuqOEkGZIe","colab_type":"code","colab":{}},"source":["# Key assumption: If one of the campaigns in a journey runs out of budget, \n","# then the conversion reward is fully lost for the entire journey\n","# including both past and future campaigns\n","\n","def simulate_budget_roi(df, budget_total, attribution, verbose=False):\n","    budgets = np.ceil(attribution * (budget_total / np.sum(attribution)))\n","    \n","    if(verbose):\n","        print(budgets)\n","    \n","    blacklist = set()\n","    conversions = set()\n","    for i in range(df.shape[0]):\n","        campaign_id = get_campaign_id(df.loc[i]['campaigns']) \n","        jid = df.loc[i]['jid']\n","        if jid not in blacklist:\n","            if budgets[campaign_id] >= 1:\n","                budgets[campaign_id] = budgets[campaign_id] - 1\n","                if(df.loc[i]['conversion'] == 1):\n","                    conversions.add(jid)\n","            else:\n","                blacklist.add(jid)\n","        \n","        if(verbose):\n","            if(i % 10000 == 0):\n","                print('{:.2%} : {:.2%} budget spent'.format(i/df.shape[0], 1.0 - np.sum(budgets)/budget_total ))\n","        \n","        if(np.sum(budgets) < budget_total * 0.02):\n","            break\n","            \n","    return len(conversions.difference(blacklist))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cSt8knKBGZIk","colab_type":"code","colab":{}},"source":["pitches = [0.1, 0.25, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0]\n","attributions = [lta, keras_logreg, lstm_a]\n","\n","for i, pitch in enumerate(pitches):\n","    for j, attribution in enumerate(attributions):\n","        reward = simulate_budget_roi(df6, 10000, attribution**pitch)\n","        print('{} {} : {}'.format(p, j, reward))"],"execution_count":0,"outputs":[]}]}